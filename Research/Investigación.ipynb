{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_Numerico/blob/master/images/C00_Img00_logo.png?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "<h1 align=\"center\">Implementación Métodos Numéricos de Jacobi y Gauss-Seidel Usando High Performance Computing</h1>\n",
    "<h2 align=\"center\">Por: Pablo Correa, Santiago Pulgarin, Ricardo Saldarriaga</h2>\n",
    "<h2 align=\"center\">2 de junio, 2021</h2>\n",
    "<h2 align=\"center\">Universidad EAFIT</h2>\n",
    "<h2 align=\"center\">MEDELLÍN - COLOMBIA </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tabla de Contenidos<span class=\"tocSkip\"></span></h2>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#PalabrasClaves\" data-toc-modified-id=\"PalabrasClaves\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Palabras Claves</a></span></li>\n",
    "        <li><span><a href=\"#Introduccion\" data-toc-modified-id=\"Introduccion\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Introducción</a></span></li>\n",
    "        <li><span><a href=\"#Objetivo\" data-toc-modified-id=\"Objetivo\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Objetivo</a></span></li>\n",
    "        <li><span><a href=\"#MarcoTeorico\" data-toc-modified-id=\"MarcoTeorico\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Marco Teorico</a></span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li><span><a href=\"#MetodoJacobi\" data-toc-modified-id=\"MetodoJacobi\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Método de <em>Jacobi</em></a></span>\n",
    "                    <ul class=\"toc-item\">\n",
    "                        <li><span><a href=\"#AlgoritmoJacobi\" data-toc-modified-id=\"AlgoritmoJacobi\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Algoritmo del método de <em>Jacobi</em></a></span></li>\n",
    "                        <li><span><a href=\"#ConvergenciaJacobi\" data-toc-modified-id=\"ConvergenciaJacobi\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Convergencia del método de <em>Jacobi</em></a></span></li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li><span><a href=\"#MetodoGaussSeidel\" data-toc-modified-id=\"MetodoSeidel\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Método de <em>Gauss - Seidel</em></a></span>\n",
    "                     <ul class=\"toc-item\">\n",
    "                        <li><span><a href=\"#AlgoritmoGaussSeidel\" data-toc-modified-id=\"AlgoritmoGaussSeidel\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Algoritmo del método de <em>Gauss - Seidel</em></a></span></li>\n",
    "                        <li><span><a href=\"#ConvergenciaGaussSeidel\" data-toc-modified-id=\"ConvergenciaGaussSeidel\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Convergencia del método de <em>Gauss - Seidel</em></a></span></li>\n",
    "                    </ul>\n",
    "                </li>   \n",
    "                <li><span><a href=\"#Forma-matricial-de-los-métodos-iterativos\" data-toc-modified-id=\"Forma-matricial-de-los-métodos-iterativos-4.4\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Nota sobre la forma matricial de los métodos iterativos</a></span></li>\n",
    "</ul></li>\n",
    "         <li><span><a href=\"#Procedimientos\" data-toc-modified-id=\"Procedimientos\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Procedimientos</a></span></li>\n",
    "         <li><span><a href=\"#Resultados\" data-toc-modified-id=\"Resultados\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Resultados</a></span></li>\n",
    "         <li><span><a href=\"#Analisis\" data-toc-modified-id=\"Analisis\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Análisis</a></span></li>\n",
    "         <li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Conclusiones</a></span></li>  \n",
    "         <li><span><a href=\"#Referencias\" data-toc-modified-id=\"Referencias\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Referencias</a></span></li> \n",
    "    </ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Palabras Claves</h2>\n",
    "<p>Lenguajes de Programación,\n",
    "HPC,\n",
    "Paralelismo,\n",
    "Análisis Numérico,\n",
    "Ecuaciones Lineales,\n",
    "Lenguajes Compilados,\n",
    "Leguajes Interpretados, MPI</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"#Introduccion\">Introducción</h2>\n",
    "<p>Hoy en día estamos acostumbrados a que todo esté al alcance de un click y que todo sea rápido. De allí, que la tecnología todos los días está evolucionando para ser más eficiente y más útil para todas las personas. Uno de esos aspectos de eficiencia, está en que se necesitan tiempos de respuesta muy rápidos para muchas de las operaciones que realizamos con nuestros dispositivos día a día. Una de las estrategias que se utilizan para lograr esta eficiencia es la computación de alto rendimiento (HPC, por sus siglas en inglés). Para contextualizar un poco: \"<i>La computación de alto rendimiento (high-performance computing o HPC en inglés) implica usar la potencia de cálculo para resolver problemas complejos en ciencia, ingeniería y gestión. Para lograr este objetivo, la computación de alto rendimiento se apoya en tecnologías computacionales como los clusters, los supercomputadores o la computación paralela. La mayoría de las ideas actuales de la computación distribuida se han basado en la computación de alto rendimiento.</i>\" (Wikipedia, 2020).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Objetivos</h2>\n",
    "<p>Siguiendo la definición de la introduccion, este proyecto tiene como objetivo hacer uso del HPC para implementar dos metodos numericos para la resolución de sistemas de ecuaciones lineales: El metodo de Jacobi y el metodo de Gauss-Seidel. Esta implementación se realizara en 3 lenguajes de programnación diferentes, esto con el objetivo de probar la eficiencia de cada uno de estos. Dichos lenguajes son: \n",
    "<ul>\n",
    "    <li>Python</li>\n",
    "    <li>C#</li>\n",
    "    <li>Julia</li>\n",
    "</ul></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Marco Teorico</h2>\n",
    "<h3>Método de Jacobi</h3>\n",
    "<p>En algebra lineal, el método de Jacobi es un algoritmo iterativo para determinar las soluciones a un sistema de ecuaciones lineales.<a href=\"https://en.wikipedia.org/wiki/Diagonally_dominant_matrix\">Estrictamente Diagonalmente Dominante</a>. De este, surge el siguiente esquema:</p>\n",
    "<br>\n",
    "$$x_i^{(k)}=\\frac{1}{a_{ii}} \\left(b_i-\\sum \\limits_{\\substack{j=1 \\\\ j\\ne i}}^n a_{i,j}x_j^{(k-1)} \\right) \\text{, con } i=1,2,3,..., n$$\n",
    "<br>\n",
    "<p>donde el superíndice $k$ indica la iteración. En el método de <strong>Jacobi</strong>, para encontrar el valor de cada $x_i^{k}$ se usan los valores de $x$ calculados en la iteración anterior, $k-1$. Por lo que es necesario siempre tener esos valores anteriores almacenados.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Algoritmo</h5><br>\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); padding:10px 0;font-family:monospace;\">\n",
    "<i>pseudocodigo</i><br>\n",
    "<font color = \"black\"><strong>Entrada:</strong> Vector inicial $x^{(0)}$, número máximo de iteraciones ($kmax$), Matriz Diagonalmente Dominante $A$, vector independiente $b$, criterio de convergencia y tolerancia.</font><br>\n",
    "<font color = \"black\"><strong>Salida:</strong> Solución cuando la convergenccia es encontrada.</font><br>\n",
    "<br>\n",
    "<font color = \"blue\">$k=0$</font><br>\n",
    "$mientras$ no haya convergencia $haga$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$i=1$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma = 0$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$j=1$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; si <font color = \"red\">$j \\neq i$ </font>entonces:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma = suma + a_{i,j}x_j^{(k)}$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin si <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$x_i^{(k+1)} = \\frac{1}{a_{i,i}}(b_i - suma)$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$k=k+1$</font><br>\n",
    "fin mientras <br>     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Convergencia</h5>\n",
    "<p>La condición de convergencia estandar (para todos los métodos iterativos) es cuando el <a href=\\\"https://en.wikipedia.org/wiki/Spectral_radius\\\">Radio Espectral</a> de la matriz de iteración es menor a 1:</p>\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/55a84dfad167d6872e52ce5b8f8cacb46c06b719\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.838ex; width:20.191ex; height:3.176ex;\" alt=\"{\\\\displaystyle \\\\rho (D^{-1}(L+U))<1.}\">\n",
    "<p> Tambien se deben cumplir las siguientes cotas para el error de la aproximación actual con respecto a la solución del sistema: \n",
    "    $$\\|\\mathbf{x}_v-\\mathbf{x}^{(k)}\\| \\leq \\|\\mathbf{T}\\|^{(k)} \\|\\mathbf{x}_v-\\mathbf{x}^{(0)}\\| \\hspace{1.5cm} \\|\\mathbf{x}_v-\\mathbf{x}^{(k)}\\| \\leq \\frac{\\|\\mathbf{T}\\|^{(k)} \\|}{1-\\|\\mathbf{T}\\|} \\| \\mathbf{x}^{(1)}-\\mathbf{x}^{(0)}\\|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Método de Gauss-Seidel</h3>\n",
    "<p>Tambien conocido como el método Liebmann, es un método iterativo que se usa para resolver sistemas de ecuaciones lineales. Es similar al método de Jacobi, aunque puede ser aplicado a cualquier matriz que no tenga elementos 0 en sus diagonales. Ademas, en el método de Gauss-Seidel se usan los valores ya calculados en la iteración actual. Con lo cual ya presenta una mejora a Jacobi. De este método resulta el siguiente esquema:</p>\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/02f26444f4da61ae84a9824a6b5292949a483fcc\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Algoritmo</h5><br>\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); padding:10px 0;font-family:monospace;\">\n",
    "<i>pseudocodigo</i><br>\n",
    "<font color = \"black\"><strong>Entrada:</strong>Matriz $A$, vector independiente $b$</font><br>\n",
    "<font color = \"black\"><strong>Salida:</strong> Solución cuando la convergenccia es encontrada.</font><br>\n",
    "<br>\n",
    "<font color = \"blue\">$k=valor para la convergencia$</font><br>\n",
    "$mientras$ no haya convergencia $haga$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$i=1$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma1 = 0$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma2 = 0$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$j=1$ hasta $i-1$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma1 = suma1 + a_{i,j}x_j^{(k)}$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$j=i$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma2 = suma2 + a_{i,j}x_j^{(k)}$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$x_i^{(k+1)} = \\frac{1}{a_{i,i}}(b_i - suma1 -suma2)$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$k=k+1$</font><br>\n",
    "fin mientras <br>     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Convergencia</h5>\n",
    "<p>La convergencia del método depende de la matriz A. Este converge si alguna de las dos condiciones se cumple:</p>\n",
    "<ul>\n",
    "    <li>A es simetrica definida-positiva</li>\n",
    "    <li>A es estrictamente diagonalmente dominante</li>\n",
    "</ul>\n",
    "<p><strong>Nota:</strong><i> En algunas ocasiones el método puede converger si aunque estas condiciones no se cumplen.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Nota sobre la forma matricial de los métodos iterativos</h3>\n",
    "<p>\n",
    "La matriz de coeficientes $\\mathbf{A}$ se puede expresar como:\n",
    "\n",
    "$$\\mathbf{A=D-L-U}$$\n",
    "donde,\n",
    "\n",
    "$\\mathbf{D}$: es una matriz que contiene únicamente los elementos de la diagonal principal $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{L}$: contiene los inversos aditivos de los elementos que están por debajo de la diagonal principal de $\\mathbf{A}$, y los demás elementos cero, $0$.\n",
    "\n",
    "$\\mathbf{U}$: contiene los inversos aditivos de los elementos que están por encima de la diagonal principal de $\\mathbf{A}$, y los demás elementos cero, $0$.</p>\n",
    "<p>Con esto anterior $\\mathbf{Ax=b}$ puede transformarse de la siguiente manera:</p>\n",
    "<img src=\"https://camo.githubusercontent.com/ae2fd54c8c0011065e57eba745645b4b87228130/68747470733a2f2f6769746875622e636f6d2f6361726c6f73616c766172657a682f416e616c697369735f4e756d657269636f2f626c6f622f6d61737465722f696d616765732f4330335f496d673137615f4974657261746976652e504e473f7261773d74727565\">\n",
    "<p>Ambas expresiones presentan la forma $\\mathbf{x=Tx+C}$.\n",
    "donde:\n",
    "\n",
    "$\\mathbf{T}$: Matriz de iteración\n",
    "\n",
    "$\\mathbf{C}$: vector constante\n",
    "\n",
    "$\\mathbf{x}^{(k)}$: $k$-ésima aproximación del vector solución $\\mathbf{x}$</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Computación de Alto Rendimiento (HPC)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Supercomputadores</h4>\n",
    "<p>Por definición, los supercomputadores son la clase de computadores mas rapida y potente disponible, son maquinas con miles de procesadores. Los computadores personales actuales (como se cuenta en este proyecto), son lo suficientemente potentes para aplicaciones cientificas y de ingeniería avanzada, por lo que tambien pueden ser considerados Computadores de Alto Rendimiento. Estos computadores deben contar con un buen balance de los siguientes elementos:</p>\n",
    "<ul>\n",
    "    <li>Unidades funcionales multietapa</li>\n",
    "    <li>Multiples Unidades Centrales de Procesamiento (CPUs) (Maquinas en Paralelo)</li>\n",
    "    <li>Multiples nucleos</li>\n",
    "    <li>Registros centrales rapidos</li>\n",
    "    <li>Memorias grandes y rapidas</li>\n",
    "    <li>Comunicación rapida entre sus unidades funcionales</li>\n",
    "    <li>Procesadores de arreglos y vectores</li>\n",
    "    <li>Software que integre bien todo lo anterior</li>\n",
    "</ul>\n",
    "<h5> Cotización Supercomputador de <em>Sylake Node</em></h5>\n",
    "<p>A continuación se presenta una estimación de costos de un supercomputador para computación de alto rendimiento, cabe aclarar que solo se presenta la configuración mas basica de este:</p>\n",
    "  <ul>\n",
    "      <li> GPU: NVIDIA V100 (32GB 5120 CUDA Cores) = 8,799.00 USD </li>\n",
    "      <li> CPU: 2x Intel Xeon G-6148 (20 Cores 2.4 GHz) = 6,435.00 USD </li>\n",
    "      <li> RAM: 96 GB a 2666 MHz = 600.00 USD </li>\n",
    "    <li> <strong>Total: 15,834.00 USD </strong></li>\n",
    "  </ul>\n",
    "  <blockquote>Con lo anterior se tienen computadores con mas de 100 nodos con estas especificaciones</blockquote>\n",
    "  <p>Esta información fue tomada de: <a href=\"https://supercomputing.iitd.ac.in/?info\">High Performance Computing at IITD</a></p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Jerarquía de memoria</h4>\n",
    "<p>Antes de explicar la jerarquía de memoria de los computadores hay que explicar como funciona el almacenamiento de las matrices, ya que no son almacenadas en bloque sino en un orden lineal, donde lenguajes como Python, Java y C lo almacenan en un orden de fila-mayor:</p>\n",
    "<p></p>\n",
    "<div>\n",
    "    <center><strong>M(0, 0) M(0, 1) M(0, 2) M(1, 0) M(1, 1) M(1, 2) M(2, 0) M(2, 1) M(2, 2)</strong></center>\n",
    "</div>\n",
    "<p></p>\n",
    "<p>Ademas, los valores de estos elementos de matrices pueden que no esten en el mismo espacio fisico. Algunos pueden estar en la RAM, otros en el Disco Duro, otros en el cache del procesador y otros en el procesador.</p>\n",
    "<p>A continuación, se presenta la jerarquía de memoria de cualquier computador. El objetivo en las maquinas mas potentes es lograr un equilibrio costo-memoria. Como se ve en la figura, la cuspide corresponde a la memoria mas cara, rapida y de menor capacidad, mientras que la base corresponde a la memoria con mayor almacenamiento, menor costo, y mas lenta.</p>\n",
    "<img src=\"https://jesusfernandeztoledo.com/wp-content/uploads/2020/01/jerarqu%C3%ADa-memoria.png\">\n",
    "<p><center>Imagen tomada de:<a href=\"https://jesusfernandeztoledo.com/jerarquia-de-memoria/\">https://jesusfernandeztoledo.com/jerarquia-de-memoria/</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Funcionamiento CPU</h4>\n",
    "<p>En la actualidad contamos con procesadores con multiples nucleos. Basicamente son dos o mas procesadores identicos conectados a una misma memoria principal, a esto se le llama <em>Symmetric multiprocessing</em>, o SMP. Cada uno de estos procesadores tiene una formula sencilla para calcular el tiempo de la CPU: </p>\n",
    "<p></p>\n",
    "<p><center><strong>CPU time</strong> = number of instructions × (cycles/instruction) × cycle time.</center></p>\n",
    "<p></p>\n",
    "<p>Donde \"CPU Time\" es el tiempo requerido por un programa, \"number of instructions\" es el total de instrucciones de nivel de máquina que el programa requiere, \"cycles/instruction\" son el número de ciclos del reloj que cada instrucción requiere, y \"cycle time\" es el tiempo que se demora la CPU en hacer un ciclo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Computación en Paralelo</h4>\n",
    "<p>En pocas palabras, la computación en paralelo es el uso simultaneo de multiples recursos de computo (Ej: Un procesador con varios nucleos) para resolver un problema <em>(Barney B,).</em></p>\n",
    "<p>A continuación se presenta una de las clasificaciones para las arquitecturas de procesamiento multiple, Taxonomía de Flynn:</p>\n",
    "<img src=\"https://hpc.llnl.gov/sites/default/files/flynnsTaxonomy.gif\">\n",
    "<p><center>Imagen tomada de: <a href=\"https://hpc.llnl.gov/sites/default/files/flynnsTaxonomy.gif\">https://hpc.llnl.gov/sites/default/files/flynnsTaxonomy.gif</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Limites y Costos de la Programación en Paralelo</h4>\n",
    "<p>La Ley de Amdahl's propone que el aumento en velocidad que pueden llegar a tener un programa esta definido por la fracción de codigo (P) que puede ser paralelizada, el número de procesadores ejecutando el trabajo (N) y el porcentaje de código secuencial:</p>\n",
    "<br>\n",
    "$$SpeedUp = \\frac{1}{\\frac{P}{N}+S}$$\n",
    "<br>\n",
    "<p>Con lo que se obtiene el siguiente grafico que nos muestra como es la subida de velocidad segun el procentaje de codigo paralelizado:</p>\n",
    "<img src=\"https://hpc.llnl.gov/sites/default/files/amdahl2_0.gif\">\n",
    "<p><center>Imagen tomada de: <a href=\"https://hpc.llnl.gov/sites/default/files/amdahl2_0.gif\">https://hpc.llnl.gov/sites/default/files/amdahl2_0.gif</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Arquitecturas de memorias de computador para paralelismo</h4>\n",
    "<div>\n",
    "    <ol>\n",
    "        <li><a href=\"https://hpc.llnl.gov/sites/default/files/shared_mem.gif\">Memoria compartida</a></li>\n",
    "        <li><a href=\"https://hpc.llnl.gov/sites/default/files/distributed_mem.gif\">Memoria distribuida</a></li>\n",
    "        <li><a href=\"https://hpc.llnl.gov/sites/default/files/hybrid_mem.gif\">Memoria hibrida Distribuida/Compartida</a></li>\n",
    "    </ol>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Modelos de Programación Paralela</h4>\n",
    "<p>Existen diferentes modelos que son comunmente usados: </p>\n",
    "<ul>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/sharedMemoryModel.gif\">Memoria compartida (Sin Hilos)</a></li>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/threadsModel2.gif\">Hilos</a></li>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/msg_pass_model.gif\">Memoria Distribuida / Paso de Mensajes</a></li>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/data_parallel_model.gif\">Paralelismo de Datos</a></li>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/hybrid_model.gif\">Hibrido</a></li>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/spmd_model.gif\">Programa Unico Datos Multiples (SPMD)</a></li>\n",
    "    <li><a href=\"https://hpc.llnl.gov/sites/default/files/mpmd_model.gif\">Programa Multiple Datos Multiples (MPMD)</a></li>\n",
    "</ul>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Comunicación Sincronica vs. Asincronica</h4>\n",
    "<p>La comunicación sincronica requiere algun tipo de \"acuerdo\" entre tareas que comparten datos. Esta comunicación es referida como comuncación en bloque, ya que un trabajo debe esperar hasta que la comuncación haya terminado.</p>\n",
    "<p>La asincronica permite que las tareas se pasen datos independientemente de una a otra. Ademas, a esta se le refiere como en No-Bloque ya que otro trabajo se puede hacer mientras que la comunicación esta en curso.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<blockquote>Para mas información sobre HPC y Paralelismo, recomendamos totalmente el uso de la documentación de <a href=\"https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial\">LIVERMORE COMPUTING CENTER</a> y los cursos de <a href=\"http://www.shodor.org/media/content/petascale/materials/UPModules/beginnersGuideHPC/moduleDocument_pdf.pdf\"> Rubin H Landau de la Universidad de Oregon.</a></blockquote>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Interfaz de Paso de Mensajes (MPI)</h4>\n",
    "<p>La MPI es un estándar que define la sintaxis y la semántica de las funciones contenidas en una biblioteca de paso de mensajes diseñada para ser usada en programas que exploten la existencia de múltiples procesadores.</p>\n",
    "<p>Con MPI el número de procesos se asigna antes de la ejecución del programa. A cada proceso se le asigna una variable que se denomina <em>rango</em>, la cual identifica a cada proceso, en el rango de 0 a p-1, donde p es el número total de procesos. El control de la ejecución del programa se realiza mediante la variable de rango. Esta permite determinar qué proceso ejecuta determinada porción de código.</p>\n",
    "<p>Las llamadas de MPI se dividen en cuatro clases:</p>\n",
    "<ol>\n",
    "    <li>Llamadas utilizadas para inicializar, administrar y finalizar comunicaciones.</li>\n",
    "    <li>Llamadas utilizadas para transferir datos entre un par de procesos.</li>\n",
    "    <li>Llamadas para transferir datos entre varios procesos.</li>\n",
    "    <li>Llamadas utilizadas para crear tipos de datos definidos por el usuario.</li>\n",
    "</ol>\n",
    "\n",
    "<p><a href=\"https://es.wikipedia.org/wiki/Interfaz_de_Paso_de_Mensajes\">Interfaz de Paso de Mensajes - Wikipedia</a></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Procedimientos</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Explicación Paralelismo Jacobi</h3>\n",
    "<p>Aplicar \"paralelismo\" a Jacobi se hace de manera sencilla ya que es un método naturalmente paralelisable debido a como se resuelve su algoritmo, el paralelismo es aplicado al hacer una distribución de las columnas en cada iteración, por lo que se pueden crear hilos y a cada una darles la tarea de calcular una parte del vector solución, que corresponde a un rango de columnas dada a cada hilo, por lo que al final que se completen todos los hilos se pueda tener el vector solución completo para la iteración.</p>\n",
    "<p>Al final de la iteración con el vector solución se busca el error relativo y se prosigue con el algoritmo, por lo que implementar el paralelismo en el método hace que funcione mucho mas eficientemente que de forma secuencial en la que un hilo debe hacer el vector solución, mientras que en el paralelo lo hacen varios hilos.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C#</h3>\n",
    "<p>C# fue el lenguaje que usamos para crear un método que nos creara un vector y una <a href=\"https://es.wikipedia.org/wiki/Matriz_de_diagonal_estrictamente_dominante\"> matriz estrictamente diagonalmente dominante</a> y se guardaran en un archivo .txt que son separadas por comas (,) y saltos de línea por cada fila</p>\n",
    "<p>Una de las razones por las que escogimos C#, es que además de ser el lenguaje más nuevo de la familia de C es que es un lenguaje seguro pero flexible, además de tener un buen manejo de la memoria teniendo una recolección de basura automática </p>\n",
    "<h4>Jacobi</h4>\n",
    "<p>Al usar el método de Jacobi, realizado con la definición <a href=\"https://en.wikipedia.org/wiki/Jacobi_method\"> Jacobi </a> del pseudocodigo y teniendo en cuenta que la matriz dada debe ser estrictamente diagonalmente dominante creamos su respectivo método en C#, además de agregarle otros parámetros, como lo son la cantidad de iteraciones a hacer y si quiere ver el resultado para cada iteración o solo la última (siendo la última iteración o en la que para por criterio de convergencia por error) en este algoritmo solo se usan librerías para poder crear matrices y vectores, mas no para sus operaciones aritméticas</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for(int p = 0; p < iterations; p++)\n",
    "            {\n",
    "                for (int i = 0; i < laMatriz.Length; i++)\n",
    "                {\n",
    "                    double sigma = 0;\n",
    "                    for (int j = 0; j < laMatriz[0].Length; j++)\n",
    "                    {\n",
    "                        if (j != i)\n",
    "                        {\n",
    "                            sigma += laMatriz[i][j] * solucion[j];\n",
    "                        }\n",
    "                    }\n",
    "                    solucion1[i] = (respuesta[i] - sigma) / laMatriz[i][i];\n",
    "                }\n",
    "            error = VectoresYMatrices.errorRelativo(solucion,solucion1);\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Jacobi Paralelo</h5>\n",
    "<p>Aplicar \"paralelismo\" a Jacobi se hace de manera sencilla ya que es un método naturalmente paralelisable debido a como se resuelve su algoritmo, el paralelismo es aplicado al hacer una distribución de las columnas, ya que para cada iteración a cada hilo se le dan un numero de columnas y estas resuelven sus respectivas columnas para al final tener el resultado completo</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Gauss-Seidel</h4>\n",
    "<p>Aplicar el método de <a href=\"https://es.wikipedia.org/wiki/M%C3%A9todo_de_Gauss-Seidel\"> Gauss-Seidel </a> en C# fue de la misma manera que como se implementó Jacobi   </p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            for(int p = 0; p < iterations; p++)\n",
    "            {\n",
    "                for (int i = 0; i < laMatriz.Length; i++)\n",
    "                {\n",
    "                    double sigma = 0;\n",
    "                    for (int j = 0; j < laMatriz[0].Length; j++)\n",
    "                    {\n",
    "                        if (j != i)\n",
    "                            sigma += laMatriz[i][j] * solucion1[j];\n",
    "                    }\n",
    "                    solucion1[i] = (respuesta[i] - sigma) / laMatriz[i][i];\n",
    "                }\n",
    "                error = VectoresYMatrices.errorRelativo(solucion,solucion1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Julia</h3>\n",
    "<p>La razón por la cual se escogió Julia es debido a que este es un lenguaje de alto nivel y desempeño tanto para la computación genérica, técnica y científica, con una sintaxis simple que proporciona facilidad a la hora de usarlo.\n",
    "Además, este dispone de un compilador avanzado (JIT) que hace que el tiempo de compilación sea más corto, mecanismos para la ejecución en paralelo y una extensa biblioteca de funciones matemáticas.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Jacobi – Secuencial</h4>\n",
    "<p>El método de Jacobi secuencial se realizó según la definición del <a href=\"https://en.wikipedia.org/wiki/Jacobi_method\">pseudocodigo</a>, en donde se cuenta con dos ciclos anidados que se encargan de realizar las iteraciones de Jacobi e ir modificando el vector de solución x y el vector solución de la iteración pasada, estos ciclos se ejecutaran tantas veces mientras el error relativo sea mayor a la tolerancia definida y el numero de iteraciones sea menor al número máximo de iteraciones.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function jacobi(A, b, x0, tol, maxiter)\n",
    "    tick()\n",
    "\n",
    "    n = size(A)[1]\n",
    "    x = copy(x0)\n",
    "    x_prev = copy(x0)\n",
    "    k = 0\n",
    "    rel_diff = tol * 2\n",
    "\n",
    "    while (rel_diff > tol) && (k < maxiter)\n",
    "        for i in range(1, n, step=1)\n",
    "            subs = 0.0\n",
    "            for j in range(1, n, step=1)\n",
    "                if i != j\n",
    "                    subs += A[i,j] * x_prev[j]\n",
    "                end\n",
    "            end\n",
    "            x[i] = (b[i] - subs) / A[i,i]   \n",
    "        end\n",
    "\n",
    "        rel_diff = norm(x - x_prev)\n",
    "        x_prev = copy(x)\n",
    "        k += 1\n",
    "    end\n",
    "\n",
    "    tock()\n",
    "    return x, rel_diff, k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Jacobi – Paralelo</h4>\n",
    "<p>\n",
    "El método de Jacobi paralelo se realizó según la definición <a href=\"https://en.wikipedia.org/wiki/Jacobi_method\">pseudocodigo</a>, en donde se cuenta con dos ciclos anidados que se encargan de realizar las iteraciones de Jacobi e ir modificando el vector de solución x y el vector solución de la iteración pasada, la diferencia con Jacobi secuencial reside en que se distribuye la responsabilidad de calcular el vector de soluciones x entre los distintos hilos que se asignan a la ejecución del algoritmo.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function jacobi(A, b, x0, tol, maxiter)\n",
    "    tick()\n",
    "\n",
    "        n = size(A)[1]\n",
    "        x = copy(x0)\n",
    "        x_prev = copy(x0)\n",
    "        k = 0\n",
    "        rel_diff = tol * 2\n",
    "        num_threads = Threads.nthreads()\n",
    "        col_mapping = Int(floor(n/num_threads))\n",
    "        rem = n%num_threads\n",
    "\n",
    "        while (rel_diff > tol) && (k < maxiter)\n",
    "\n",
    "            if rem == 0\n",
    "                @threads for j in 0:(Threads.nthreads())-1\n",
    "                    jacobi_task(A, b, x, x_prev, (j*col_mapping)+1, (j*col_mapping)+col_mapping)\n",
    "                end\n",
    "            else \n",
    "                @threads for j in 0:(Threads.nthreads())-2\n",
    "                    jacobi_task(A, b, x, x_prev, (j*col_mapping)+1, (j*col_mapping)+col_mapping)\n",
    "                end\n",
    "                @threads for _ in 1:1\n",
    "                    jacobi_task(A, b, x, x_prev, ((num_threads-1)*col_mapping)+1, ((num_threads-1)*col_mapping)+col_mapping+rem)\n",
    "                end\n",
    "            end\n",
    "        \n",
    "            rel_diff = norm(x - x_prev)\n",
    "            x_prev = copy(x)\n",
    "            k += 1\n",
    "        end\n",
    "\n",
    "    tock()\n",
    "    print(k)\n",
    "    return x, rel_diff, k\n",
    "end\n",
    "\n",
    "function jacobi_task(A, b, x, x_prev, lower_limit, upper_limit)\n",
    "    for i=lower_limit:upper_limit\n",
    "        subs = 0.0\n",
    "        for j in 1:size(A)[1]\n",
    "            if (j != i)\n",
    "                subs += A[i,j] * x_prev[j]\n",
    "            end\n",
    "        end\n",
    "        x[i] = (b[i] - subs) / A[i,i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Gauss Seidel - Secuencial</h4>\n",
    "<p>El método de Gauss Seidel secuencial se realizó según la definición del <a href=\"https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method\">pseudocodigo</a>, en donde se cuenta con dos ciclos anidados que se encargan de realizar las iteraciones de Gauss Seidel, debido a su naturaleza se genera una optimización con respecto a jacobi debido a que este método utiliza los valores del vector de solución x ya calculados en la presente iteración para realizar el calculo de los faltantes.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "function gauss_seidel(A, b, x0, tol, maxiter)\n",
    "    tick()\n",
    "\n",
    "    n = size(A)[1]\n",
    "    x = copy(x0)\n",
    "    x_prev = copy(x0)\n",
    "    k = 0\n",
    "    rel_diff = tol * 2\n",
    "\n",
    "    while (rel_diff > tol) && (k < maxiter)\n",
    "        for i in range(1, n, step=1)\n",
    "            subs = 0.0\n",
    "            for j in range(1, n, step=1)\n",
    "                if j < i\n",
    "                    subs += A[i, j] * x[j]\n",
    "                elseif j > i\n",
    "                    subs += A[i, j] * x_prev[j]\n",
    "                else\n",
    "                end\n",
    "            end  \n",
    "            x[i] = (b[i] - subs) / A[i,i]\n",
    "        end\n",
    "\n",
    "        rel_diff = norm(x - x_prev)\n",
    "        x_prev = copy(x)\n",
    "        k += 1\n",
    "    end\n",
    "\n",
    "    tock()\n",
    "    return x, rel_diff, k\n",
    "end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Python</h3>\n",
    "<p>Como ya se sabe, Python es uno de los lenguajes de programación mas utilizados en la actualidad, en especial en las ciencia de datos gracias a su facilidad y excelentes librería para la ingesta y analítica de estos. Por ello fue uno de los lenguajes seleccionados en primer momento. Es importante aclarar lo vital que fue la implementación de la librería <em>numpy</em> en nuestros algoritmos (en uno mas que en otros), ya que dentro del HPC de Python es uno de los principios basicos dentro de las implementaciones. Pero, a diferencia de los otros lenguajes este es del paradigma Interpretado, por lo que sus comportamientos pueden ser diferentes.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Jacobi</h4>\n",
    "<p>Para el método de Jacobi, el cual es el foco principal de nuestra investigación, se implementaron 3 algoritmos diferentes. Puesto que con cada uno de ellos la aproximación al problema fue diferente y sus tiempos de ejecución tambien.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Jacobi Secuencial</h5>\n",
    "<p>Para este algoritmo hicimos uso del pseudocodigo inicial, descrito en el marco teorico. Fue una aproximación bastante trivial, como se puede ver acontinuación:</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACLARACIÓN: Este es un codigo ilustritivo, si se desea utilizarlo hacer uso del programa adjunto a esta investigación\n",
    "def jacobi(a, b, x, tolerance, kmax):\n",
    "    n = a.shape[0]\n",
    "    k = 1\n",
    "\n",
    "    while k < kmax:\n",
    "        x_old  = x.copy()\n",
    "        for i in range(n):\n",
    "            suma = 0\n",
    "            for j in range(n):\n",
    "                if j != i:\n",
    "                    suma += a[i,j]*x[j]\n",
    "            x[i] = (b[i] - suma) / a[i,i]        \n",
    "        k += 1\n",
    "        if np.linalg.norm(x - x_old, ord=np.inf) / np.linalg.norm(x, ord=np.inf) < tolerance: #se verifica la tolerancia para ver si hubo convergencia\n",
    "            break\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Jacobi Paralelo</h5>\n",
    "<p>En cuanto a esta versión del algoritmo, haciendo uso de tecnicas de paralelismo como parte esencial del HPC, se utilizó el mismo algoritmo trivial del punto anterior, pero se definen unos rangos de acción para cada hilo (ver explicación en el apartado de Explicación Paralelismo Jacobi). La complicación de esta implementación esta en como funcionan los hilos en python, ya que, como nuestro codigo era ligado a la CPU, ya que solo un hilo puede tener \"Global Interpreter Lock\", por lo que los hilos en verdad no se al mismo tiempo, sino en un tipo de secuencialidad, lo cual hace que se tengan que recurrir a <a href=\"https://docs.python.org/3/library/multiprocessing.html\"><code>Processes</code></a>. Estos, se ejecutan por separado en cada procesador logico de la CPU. El problema radica en que, por las caracteristicas que tiene el metodo de Jacobi (necesita una comunicación sincronica porque es un algoritmo dependiente a los datos anteriores) y la experticia con la que contabamos en el tema, no encontramos una forma de implementar el metodo de Jacobi de maner asincronica (haciendo uso del <a href=\"https://docs.python.org/3/library/multiprocessing.html#multiprocessing.pool.Pool.apply_async\"> metodo apply_async()</a>), o sea, con un paralelismo \"real\". Sin embargo, haciendo uso de <a href=\"https://docs.python.org/es/3/library/threading.html\"><code>Threading</code></a> se llego a una aproximación que si reduce el tiempo de ejecución considerablemente.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACLARACIÓN: el meotodo jacobi con el cual se inicia el hilo es el mismo que se describio anteriormente\n",
    "    \n",
    "        bloques = int(len(A[0]))/10\n",
    "\n",
    "        if (len(A[0])%10 == 0):\n",
    "            hilos = 10\n",
    "            \n",
    "        for k in range(max_iterations):\n",
    "            x_old = x.copy()\n",
    "            list_threads = []\n",
    "            i=0\n",
    "            j=1\n",
    "            #Numero Maximo de Procesos es p-1, Ya que la maquina cuenta con 12 procesadores logicos\n",
    "            for num_thread in range(1, hilos+1):\n",
    "                if( num_thread == 11 ):\n",
    "                    t = threading.Thread(target=jacobi, args=(A,b,x,int(bloques*j),len(A[0]),)) #Se inicializa cada hilo\n",
    "                    list_threads.append(t)\n",
    "                    t.start()#Comienzan los procesos de cada hilo\n",
    "                elif(len(A[0])<10):\n",
    "                    t = threading.Thread(target=jacobi, args=(A,b,x,0,len(A[0]),))\n",
    "                    list_threads.append(t)\n",
    "                    t.start()\n",
    "                    break\n",
    "                else:\n",
    "                    t = threading.Thread(target=jacobi, args=(A,b,x,int(bloques*i),int(bloques*j),))\n",
    "                    list_threads.append(t)\n",
    "                    t.start()\n",
    "                i+=1\n",
    "                j+=1\n",
    "            \n",
    "\n",
    "            for t in list_threads:\n",
    "                t.join() #Termina los procesos de cada procesador       \n",
    "\n",
    "            if np.linalg.norm(x - x_old, ord=np.inf) / np.linalg.norm(x, ord=np.inf) < tolerance: #se verifica la tolerancia para ver si hubo convergencia\n",
    "                break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Jacobi HPC</h5>\n",
    "<p>En este caso se utilizo de manera muy provechosa la librería numpy, ya que hicimos uso de métodos de extrema eficiencia. El punto fundamental de esta implementación esta en que se cambio el algoritmo trivial y se hizo uso de la forma matricial: $\\mathbf{x=Tx+C}$. Lo cual hace que las iteraciones funcionen de una manera diferente. Ademas, se hace uso de los métodos: <code>dot()</code>,<code>diag()</code>,<code>linalg.norm()</code>. A continuación, se muestra en el codigo, esta implementación esta basada en la documentación por parte de la Universidad de Texas, en su articulo: <a href=\"https://johnfoster.pge.utexas.edu/numerical-methods-book/LinearAlgebra_IterativeSolvers.html\">Iterative Methods for Solving Linear Systems of Equations</a>.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ACLARACIÓN: Este es un codigo ilustritivo, si se desea utilizarlo hacer uso del programa adjunto a esta investigación\n",
    "\n",
    "def jacobi(A, b, tolerance, max_iterations):\n",
    "\n",
    "    x = np.zeros_like(b, dtype=np.double)# Se crea un arreglo de 0s del mismo tamaño de b\n",
    "    #x = Tx + C\n",
    "    T = A - np.diag(np.diagonal(A)) #Se crea la matriz de iteraciones\n",
    "    \n",
    "    for k in range(max_iterations):\n",
    "        \n",
    "        x_old  = x.copy() #Se copia la x vieja para el calculo de la convergencia\n",
    "        \n",
    "        x = (b - np.dot(T, x)) / np.diagonal(A) #Se calcula el x -> b-suma/aii, por medio del producto punto de T con x\n",
    "\n",
    "        if np.linalg.norm(x - x_old, ord=np.inf) / np.linalg.norm(x, ord=np.inf) < tolerance: #se verifica la tolerancia para ver si hubo convergencia\n",
    "            break\n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Gauss-Seidel</h5>\n",
    "<p>Al igual que con el Jacobi HPC, aquí hacemos uso del método dot() de numpy, con lo que podemos operar de una manera muy rapida la matriz. En esta implmentación se sigue haciendo uso de la implementación trivial descrita en el marco teorico, mas fueron implmentados estas mejoras de numpy para mejorar significativamente el rendimiento.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gauss_seidel(A, b, tolerance, max_iterations):\n",
    "    t0 = time.time()\n",
    "    x = np.zeros_like(b, dtype=np.double)\n",
    "    \n",
    "    #Ciclo para revisar iteraciones maximas\n",
    "    for k in range(max_iterations):\n",
    "        \n",
    "        x_old  = x.copy()\n",
    "        \n",
    "        #Se itera en cada fila\n",
    "        for i in range(A.shape[0]):\n",
    "            x[i] = (b[i] - np.dot(A[i,:i], x[:i]) - np.dot(A[i,(i+1):], x_old[(i+1):])) / A[i,i] #xi=(bi-suma1-suma2)/Ai,i\n",
    "            \n",
    "        #Condición de Parada \n",
    "        if np.linalg.norm(x - x_old, ord=np.inf) / np.linalg.norm(x, ord=np.inf) < tolerance:\n",
    "            break\n",
    "    \n",
    "    t1 = time.time()\n",
    "\n",
    "    total = t1-t0\n",
    "    print(total)        \n",
    "    return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resultados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>Para mantener el orden y el entendimiento del documento investigativo, los resultados son entregados anexos a este notebook en un archivo de excel que se pueden encontrar en este <a href=\"https://docs.google.com/spreadsheets/d/169AFDOGrb3Yb57YCi1vQi37TsnYm1Oy10I1kLIm0xTM/edit?usp=sharing\">enlace</a> o revisando el apartado de anexos.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Analísis de Resultados</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C#</h3>\n",
    "<p>Como podemos ver en los resultados dados con una matriz de 10000 datos y su respectivo vector para los métodos de Jacobi y Gauss-Seidel podemos ver una leve incoherencia a lo que debería ser la realidad, debido a que el método de Gauss-Seidel debería demorar menos que el método de Jacobi secuencial, lo cual en el promedio si se da, pero no por mucha diferencia, en los resultados podemos ver que la diferencia da por solo 23.5 ms entre un método y otro.<p/>\n",
    "<p>Ahora comparando estos resultados con el del Jacobi paralelo podemos ver un gran cambio, y como darle responsabilidad no a un solo hilo sino a varios para hacer el método mas eficiente se ve reflejado en la rapidez del algoritmo con una diferencia de 1543.7 ms frente a Jacobi secuencial y de 1520.2 ms frente a Gauss-Seidel.<p/>\n",
    "<p>Por lo que podemos concluir que emplear el método de paralelismo en Jacobi es la forma más eficiente del método entre los 3 métodos empleados en C#.</p>\n",
    "<h5>Complejidad Jacobi Secuencial</h5>\n",
    "<p>Para la solución Jacobi podemos ver que se usan 3 ciclos anidados, podemos ver que el ciclo anidado mas interno se da con el tamaño de la matriz al cuadrado n^2, y el ciclo externo es un ciclo que se repite el numero de iteraciones dadas, por lo que el orden de la solución de Jacobi es de <strong>O(k*n^2)</strong> , siendo k el número de iteraciones y n el tamaño de la matriz.</p>\n",
    "<h5>Complejidad Gauss-Seidel</h5>\n",
    "<p>Para la solución Gauss-Seidel podemos ver que se usan 3 ciclos anidados, podemos ver que el ciclo anidado más interno se da con el tamaño de la matriz al cuadrado n^2, y el ciclo externo es un ciclo que se repite el número de iteraciones dadas, por lo que el orden de la solución de Gauss-Seidel es de <strong>O(k*n^2)</strong>, siendo k el número de iteraciones y n el tamaño de la matriz.</p>\n",
    "<h5>Complejidad Jacobi Paralelo</h5>\n",
    "<p>Para la solución de Jacobi Paralelo tenemos que cada hilo hace un numero de columnas, este número este dado por el tamaño de la matriz dividido entre 12, este numero lo llamaremos h, y al igual que en Jacobi tenemos a k como el número de iteraciones y a n como el tamaño de la matriz, por lo que el orden de la solución para Jacobi Paralelo es de O(k*n*h) siendo este orden mucho menor que el de Jacobi ya que siempre h << n.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Python</h3>\n",
    "<p> Como se observa en los resultados obtenidos, python es un poco diferente a sus resultados con respecto a los otros lenguajes aunque se este usando el mismo algoritmo para todos. Esto, desde nuestro conocimiento se debe a varias razones, una de estas es por la condición que tiene python como lenguaje  interpretado y por la memoria heap que maneja, lo cual como siempre se esta haciendo el mismo proceso se vuelve lento, a diferencia de los otros lenguajes que son compilados. Tambien, cuando se evalua los metodos de Jacobi de Paralelo, python se encuentra el ultimo lugar, principalmente por lo que se hablaba en el procedimiento sobre como python aplica los hilos.</p>\n",
    "<p>Sin embargo, una vez entramos a los metodos optimizaddos encontramos que python es el que tiene el mejor rendimiento, principalmente gracias a los metodos de numpy, ya que con esos se consiguen uina complejidad en el metodo de Jacobi de HPC de O(n*k)</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Julia</h3>\n",
    "<p>Los resultados para Julia fueron los siguientes:\n",
    "Para Jacobi Secuencial se realizaron un total de 10 corridas para el algoritmo utilizando la matriz estrictamente diagonalmente dominante de 10000x10000, en donde se pueden observar los tiempos de ejecución obtenidos en la tabla con un tiempo promedio de 2,834 segundos.</p>\n",
    "<p>Para Gauss-Seidel Secuencial se realizaron un total de 10 corridas para el algoritmo utilizando la matriz estrictamente diagonalmente dominante de 10000x10000, en donde se pueden observar los tiempos de ejecución obtenidos en la tabla con un tiempo promedio de 2,098 segundos.</p>\n",
    "<p>Para Jacobi Paralelo se realizaron un total de 10 corridas utilizando 12 threads para el algoritmo utilizando la matriz estrictamente diagonalmente dominante de 10000x10000, en donde se pueden observar los tiempos de ejecución obtenidos en la tabla con un tiempo promedio de 0,931 segundos.</p>\n",
    "<p>De acuerdo con los resultados obtenidos se puede evidenciar que la implementación paralela del método de Jacobi permitió triplicar la velocidad de ejecución con respecto a el método secuencial y también duplicar este tiempo con respecto a Gauss Seidel, todo esto gracias a la división de trabajo que se generó desde la construcción del método paralelo y el porcentaje de código secuencial que se logró paralelizar.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusión</h2>\n",
    "<p>Después de analizar todos los resultados de los 3 lenguajes y la investigación plasmada en este documento podemos concluir que el método de Jacobi Paralelo en el lenguaje de C# es el más eficaz seguido de Julia y por último de Python, debido a su velocidad de compilación y ejecución una característica de la familia de C, pero además de esto de uno de sus aspectos importantes y es el hecho de su efectividad en el buen manejo de la memoria teniendo una recolección de basura automática.\n",
    "Es por esto que para una eventual implementación de estos algoritmos en plataformas reales de computación distribuida y de alto rendimiento sería ideal la utilización de lenguajes compilados versus interpretados.</p>\n",
    "<p>Finalmente se pudo visualizar la importancia que posee el HPC visto desde una perspectiva del paralelismo dentro de la solución de problemas numéricos, esto debido a la optimización que se puede generar a nivel de tiempo de ejecución lo que finalmente se traduce en disminución de costos para los proyectos que tratan con temas relacionados.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Anexos</h2>\n",
    "<h4>GitHub del Poryecto:<a href=\"https://github.com/PabloCorrea99/NumericMethods_Project\">https://github.com/PabloCorrea99/NumericMethods_Project</a></h4>\n",
    "<h4>Excel de los resultados: <a href=\"https://docs.google.com/spreadsheets/d/169AFDOGrb3Yb57YCi1vQi37TsnYm1Oy10I1kLIm0xTM/edit?usp=sharing\">https://docs.google.com/spreadsheets/d/169AFDOGrb3Yb57YCi1vQi37TsnYm1Oy10I1kLIm0xTM/edit?usp=sharing</a></h4>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Referencias:</h2>\n",
    "<ol>\n",
    " <li>https://es.wikipedia.org/wiki/Computaci%C3%B3n_de_alto_rendimiento</li>\n",
    " <li>https://en.wikipedia.org/wiki/Jacobi_method</li>                      <li>https://en.wikipedia.org/wiki/Diagonally_dominant_matrix</li>      <li>https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method</li>\n",
    " <li>https://numpy.org/devdocs</li>\n",
    " <li>https://supercomputing.iitd.ac.in/?info</li>\n",
    " <li>https://jesusfernandeztoledo.com/jerarquia-de-memoria/</li>\n",
    " <li>https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial</li>\n",
    "<li>http://www.shodor.org/media/content/petascale/materials/UPModules/beginnersGuideHPC/moduleDocument_pdf.pdf</li>\n",
    "    <li>https://johnfoster.pge.utexas.edu/numerical-methods-book/LinearAlgebra_IterativeSolvers.html</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
