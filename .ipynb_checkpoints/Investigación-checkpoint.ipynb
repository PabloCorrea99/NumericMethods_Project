{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p float=\"center\">\n",
    "  <img src=\"https://github.com/carlosalvarezh/Analisis_Numerico/blob/master/images/C00_Img00_logo.png?raw=true\" width=\"350\" />\n",
    "</p>\n",
    "<h1 align=\"center\">Implementación Métodos Numéricos de Jacobi y Gauss-Seidel Usando High Performance Computing</h1>\n",
    "<h2 align=\"center\">Por: Pablo Correa, Santiago Pulgarin, Ricardo Saldarriaga</h2>\n",
    "<h2 align=\"center\">18 de mayo, 2021</h2>\n",
    "<h2 align=\"center\">Universidad EAFIT</h2>\n",
    "<h2 align=\"center\">MEDELLÍN - COLOMBIA </h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Tabla de Contenidos<span class=\"tocSkip\"></span></h2>\n",
    "<div class=\"toc\">\n",
    "    <ul class=\"toc-item\">\n",
    "        <li><span><a href=\"#Resumen\" data-toc-modified-id=\"Resumen\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Resumen</a></span></li>\n",
    "        <li><span><a href=\"#Abstract\" data-toc-modified-id=\"Abstract\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Abstract</a></span></li>\n",
    "        <li><span><a href=\"#PalabrasClaves\" data-toc-modified-id=\"PalabrasClaves\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Palabras Claves</a></span></li>\n",
    "        <li><span><a href=\"#Introduccion\" data-toc-modified-id=\"Introduccion\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Introducción</a></span></li>\n",
    "        <li><span><a href=\"#Objetivo\" data-toc-modified-id=\"Objetivo\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Objetivo</a></span></li>\n",
    "        <li><span><a href=\"#MarcoTeorico\" data-toc-modified-id=\"MarcoTeorico\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Marco Teorico</a></span>\n",
    "            <ul class=\"toc-item\">\n",
    "                <li><span><a href=\"#MetodoJacobi\" data-toc-modified-id=\"MetodoJacobi\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>Método de <em>Jacobi</em></a></span>\n",
    "                    <ul class=\"toc-item\">\n",
    "                        <li><span><a href=\"#AlgoritmoJacobi\" data-toc-modified-id=\"AlgoritmoJacobi\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Algoritmo del método de <em>Jacobi</em></a></span></li>\n",
    "                        <li><span><a href=\"#ConvergenciaJacobi\" data-toc-modified-id=\"ConvergenciaJacobi\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Convergencia del método de <em>Jacobi</em></a></span></li>\n",
    "                    </ul>\n",
    "                </li>\n",
    "                <li><span><a href=\"#MetodoGaussSeidel\" data-toc-modified-id=\"MetodoSeidel\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;</span>Método de <em>Gauss - Seidel</em></a></span>\n",
    "                     <ul class=\"toc-item\">\n",
    "                        <li><span><a href=\"#AlgoritmoGaussSeidel\" data-toc-modified-id=\"AlgoritmoGaussSeidel\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;</span>Algoritmo del método de <em>Gauss - Seidel</em></a></span></li>\n",
    "                        <li><span><a href=\"#ConvergenciaGaussSeidel\" data-toc-modified-id=\"ConvergenciaGaussSeidel\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;</span>Convergencia del método de <em>Gauss - Seidel</em></a></span></li>\n",
    "                    </ul>\n",
    "                </li>   \n",
    "                <li><span><a href=\"#Forma-matricial-de-los-métodos-iterativos\" data-toc-modified-id=\"Forma-matricial-de-los-métodos-iterativos-4.4\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;</span>Nota sobre la forma matricial de los métodos iterativos</a></span></li>\n",
    "</ul></li>\n",
    "         <li><span><a href=\"#Procedimientos\" data-toc-modified-id=\"Procedimientos\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Procedimientos</a></span></li>\n",
    "         <li><span><a href=\"#Resultados\" data-toc-modified-id=\"Resultados\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Resultados</a></span></li>\n",
    "         <li><span><a href=\"#Analisis\" data-toc-modified-id=\"Analisis\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Análisis</a></span></li>\n",
    "         <li><span><a href=\"#Conclusiones\" data-toc-modified-id=\"Conclusiones\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Conclusiones</a></span></li>  \n",
    "         <li><span><a href=\"#Referencias\" data-toc-modified-id=\"Referencias\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Referencias</a></span></li> \n",
    "    </ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Resumen</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Abstract</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Palabras Claves</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 class=\"#Introduccion\">Introducción</h2>\n",
    "<p>Hoy en día estamos acostumbrados a que todo esté al alcance de un click y que todo sea rápido. De allí, que la tecnología todos los días está evolucionando para ser más eficiente y más útil para todas las personas. Uno de esos aspectos de eficiencia, está en que se necesitan tiempos de respuesta muy rápidos para muchas de las operaciones que realizamos con nuestros dispositivos día a día. Una de las estrategias que se utilizan para lograr esta eficiencia es la computación de alto rendimiento (HPC, por sus siglas en inglés). Para contextualizar un poco: \"<i>La computación de alto rendimiento (high-performance computing o HPC en inglés) implica usar la potencia de cálculo para resolver problemas complejos en ciencia, ingeniería y gestión. Para lograr este objetivo, la computación de alto rendimiento se apoya en tecnologías computacionales como los clusters, los supercomputadores o la computación paralela. La mayoría de las ideas actuales de la computación distribuida se han basado en la computación de alto rendimiento.</i>\" (Wikipedia, 2020).</p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Objetivos</h2>\n",
    "<p>Siguiendo la definición de la introduccion, este proyecto tiene como objetivo hacer uso del HPC para implementar dos metodos numericos para la resolución de sistemas de ecuaciones lineales: El metodo de Jacobi y el metodo de Gauss-Seidel. Esta implementación se realizara en 3 lenguajes de programnación diferentes, esto con el objetivo de probar la eficiencia de cada uno de estos. Dichos lenguajes son: \n",
    "<ul>\n",
    "    <li>Python</li>\n",
    "    <li>C#</li>\n",
    "    <li>Julia</li>\n",
    "</ul></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Marco Teorico</h2>\n",
    "<h3>Método de Jacobi</h3>\n",
    "<p>En algebra lineal, el método de Jacobi es un algoritmo iterativo para determinar las soluciones a un sistema de ecuaciones lineales.<a href=\"https://en.wikipedia.org/wiki/Diagonally_dominant_matrix\">Estrictamente Diagonalmente Dominante</a>. De este, surge el siguiente esquema:</p>\n",
    "<br>\n",
    "$$x_i^{(k)}=\\frac{1}{a_{ii}} \\left(b_i-\\sum \\limits_{\\substack{j=1 \\\\ j\\ne i}}^n a_{i,j}x_j^{(k-1)} \\right) \\text{, con } i=1,2,3,..., n$$\n",
    "<br>\n",
    "<p>donde el superíndice $k$ indica la iteración. En el método de <strong>Jacobi</strong>, para encontrar el valor de cada $x_i^{k}$ se usan los valores de $x$ calculados en la iteración anterior, $k-1$. Por lo que es necesario siempre tener esos valores anteriores almacenados.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Algoritmo</h5><br>\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); padding:10px 0;font-family:monospace;\">\n",
    "<i>pseudocodigo</i><br>\n",
    "<font color = \"black\"><strong>Entrada:</strong> Vector inicial $x^{(0)}$, número máximo de iteraciones ($kmax$), Matriz Diagonalmente Dominante $A$, vector independiente $b$, criterio de convergencia y tolerancia.</font><br>\n",
    "<font color = \"black\"><strong>Salida:</strong> Solución cuando la convergenccia es encontrada.</font><br>\n",
    "<br>\n",
    "<font color = \"blue\">$k=0$</font><br>\n",
    "$mientras$ no haya convergencia $haga$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$i=1$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma = 0$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$j=1$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; si <font color = \"red\">$j \\neq i$ </font>entonces:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma = suma + a_{i,j}x_j^{(k)}$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin si <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$x_i^{(k+1)} = \\frac{1}{a_{i,i}}(b_i - suma)$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$k=k+1$</font><br>\n",
    "fin mientras <br>     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Convergencia</h5>\n",
    "<p>La condición de convergencia estandar (para todos los métodos iterativos) es cuando el <a href=\\\"https://en.wikipedia.org/wiki/Spectral_radius\\\">Radio Espectral</a> de la matriz de iteración es menor a 1:</p>\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/55a84dfad167d6872e52ce5b8f8cacb46c06b719\" class=\"mwe-math-fallback-image-inline\" aria-hidden=\"true\" style=\"vertical-align: -0.838ex; width:20.191ex; height:3.176ex;\" alt=\"{\\\\displaystyle \\\\rho (D^{-1}(L+U))<1.}\">\n",
    "<p> Tambien se deben cumplir las siguientes cotas para el error de la aproximación actual con respecto a la solución del sistema: \n",
    "    $$\\|\\mathbf{x}_v-\\mathbf{x}^{(k)}\\| \\leq \\|\\mathbf{T}\\|^{(k)} \\|\\mathbf{x}_v-\\mathbf{x}^{(0)}\\| \\hspace{1.5cm} \\|\\mathbf{x}_v-\\mathbf{x}^{(k)}\\| \\leq \\frac{\\|\\mathbf{T}\\|^{(k)} \\|}{1-\\|\\mathbf{T}\\|} \\| \\mathbf{x}^{(1)}-\\mathbf{x}^{(0)}\\|$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Método de Gauss-Seidel</h3>\n",
    "<p>Tambien conocido como el método Liebmann, es un método iterativo que se usa para resolver sistemas de ecuaciones lineales. Es similar al método de Jacobi, aunque puede ser aplicado a cualquier matriz que no tenga elementos 0 en sus diagonales. Ademas, en el método de Gauss-Seidel se usan los valores ya calculados en la iteración actual. Con lo cual ya presenta una mejora a Jacobi. De este método resulta el siguiente esquema:</p>\n",
    "<img src=\"https://wikimedia.org/api/rest_v1/media/math/render/svg/02f26444f4da61ae84a9824a6b5292949a483fcc\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Algoritmo</h5><br>\n",
    "<div style=\"background-color:rgba(0, 0, 0, 0.0470588); padding:10px 0;font-family:monospace;\">\n",
    "<i>pseudocodigo</i><br>\n",
    "<font color = \"black\"><strong>Entrada:</strong>Matriz $A$, vector independiente $b$</font><br>\n",
    "<font color = \"black\"><strong>Salida:</strong> Solución cuando la convergenccia es encontrada.</font><br>\n",
    "<br>\n",
    "<font color = \"blue\">$k=valor para la convergencia$</font><br>\n",
    "$mientras$ no haya convergencia $haga$:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$i=1$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma1 = 0$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma2 = 0$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$j=1$ hasta $i-1$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma1 = suma1 + a_{i,j}x_j^{(k)}$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; desde <font color = \"red\">$j=i$ hasta $n$ </font>haga:<br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$suma2 = suma2 + a_{i,j}x_j^{(k)}$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$x_i^{(k+1)} = \\frac{1}{a_{i,i}}(b_i - suma1 -suma2)$</font><br>\n",
    "&nbsp;&nbsp;&nbsp;&nbsp; fin desde <br>     \n",
    "&nbsp;&nbsp;&nbsp;&nbsp; <font color = \"blue\">$k=k+1$</font><br>\n",
    "fin mientras <br>     \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Convergencia</h5>\n",
    "<p>La convergencia del método depende de la matriz A. Este converge si alguna de las dos condiciones se cumple:</p>\n",
    "<ul>\n",
    "    <li>A es simetrica definida-positiva</li>\n",
    "    <li>A es estrictamente diagonalmente dominante</li>\n",
    "</ul>\n",
    "<p><strong>Nota:</strong><i> En algunas ocasiones el método puede converger si aunque estas condiciones no se cumplen.</i></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Nota sobre la forma matricial de los métodos iterativos</h3>\n",
    "<p>\n",
    "La matriz de coeficientes $\\mathbf{A}$ se puede expresar como:\n",
    "\n",
    "$$\\mathbf{A=D-L-U}$$\n",
    "donde,\n",
    "\n",
    "$\\mathbf{D}$: es una matriz que contiene únicamente los elementos de la diagonal principal $\\mathbf{A}$\n",
    "\n",
    "$\\mathbf{L}$: contiene los inversos aditivos de los elementos que están por debajo de la diagonal principal de $\\mathbf{A}$, y los demás elementos cero, $0$.\n",
    "\n",
    "$\\mathbf{U}$: contiene los inversos aditivos de los elementos que están por encima de la diagonal principal de $\\mathbf{A}$, y los demás elementos cero, $0$.</p>\n",
    "<p>Con esto anterior $\\mathbf{Ax=b}$ puede transformarse de la siguiente manera:</p>\n",
    "<img src=\"https://camo.githubusercontent.com/ae2fd54c8c0011065e57eba745645b4b87228130/68747470733a2f2f6769746875622e636f6d2f6361726c6f73616c766172657a682f416e616c697369735f4e756d657269636f2f626c6f622f6d61737465722f696d616765732f4330335f496d673137615f4974657261746976652e504e473f7261773d74727565\">\n",
    "<p>Ambas expresiones presentan la forma $\\mathbf{x=Tx+C}$.\n",
    "donde:\n",
    "\n",
    "$\\mathbf{T}$: Matriz de iteración\n",
    "\n",
    "$\\mathbf{C}$: vector constante\n",
    "\n",
    "$\\mathbf{x}^{(k)}$: $k$-ésima aproximación del vector solución $\\mathbf{x}$</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Computación de Alto Rendimiento (HPC)</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Supercomputadores</h4>\n",
    "<p>Por definición, los supercomputadores son la clase de computadores mas rapida y potente disponible, son maquinas con miles de procesadores. Los computadores personales actuales (como se cuenta en este proyecto), son lo suficientemente potentes para aplicaciones cientificas y de ingeniería avanzada, por lo que tambien pueden ser considerados Computadores de Alto Rendimiento. Estos computadores deben contar con un buen balance de los siguientes elementos:</p>\n",
    "<ul>\n",
    "    <li>Unidades funcionales multietapa</li>\n",
    "    <li>Multiples Unidades Centrales de Procesamiento (CPUs) (Maquinas en Paralelo)</li>\n",
    "    <li>Multiples nucleos</li>\n",
    "    <li>Registros centrales rapidos</li>\n",
    "    <li>Memorias grandes y rapidas</li>\n",
    "    <li>Comunicación rapida entre sus unidades funcionales</li>\n",
    "    <li>Procesadores de arreglos y vectores</li>\n",
    "    <li>Software que integre bien todo lo anterior</li>\n",
    "</ul>\n",
    "<h5> Cotización Supercomputador de <em>Sylake Node</em></h5>\n",
    "<p>A continuación se presenta una estimación de costos de un supercomputador para computación de alto rendimiento, cabe aclarar que solo se presenta la configuración mas basica de este:</p>\n",
    "  <ul>\n",
    "      <li> GPU: NVIDIA V100 (32GB 5120 CUDA Cores) = 8,799.00 USD </li>\n",
    "      <li> CPU: 2x Intel Xeon G-6148 (20 Cores 2.4 GHz) = 6,435.00 USD </li>\n",
    "      <li> RAM: 96 GB a 2666 MHz = 600.00 USD </li>\n",
    "    <li> <strong>Total: 15,834.00 USD </strong></li>\n",
    "  </ul>\n",
    "  <blockquote>Con lo anterior se tienen computadores con mas de 100 nodos con estas especificaciones</blockquote>\n",
    "  <p>Esta información fue tomada de: <a href=\"https://supercomputing.iitd.ac.in/?info\">High Performance Computing at IITD</a></p>\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Jerarquía de memoria</h4>\n",
    "<p>Antes de explicar la jerarquía de memoria de los computadores hay que explicar como funciona el almacenamiento de las matrices, ya que no son almacenadas en bloque sino en un orden lineal, donde lenguajes como Python, Java y C lo almacenan en un orden de fila-mayor:</p>\n",
    "<p></p>\n",
    "<div>\n",
    "    <center><strong>M(0, 0) M(0, 1) M(0, 2) M(1, 0) M(1, 1) M(1, 2) M(2, 0) M(2, 1) M(2, 2)</strong></center>\n",
    "</div>\n",
    "<p></p>\n",
    "<p>Ademas, los valores de estos elementos de matrices pueden que no esten en el mismo espacio fisico. Algunos pueden estar en la RAM, otros en el Disco Duro, otros en el cache del procesador y otros en el procesador.</p>\n",
    "<p>A continuación, se presenta la jerarquía de memoria de cualquier computador. El objetivo en las maquinas mas potentes es lograr un equilibrio costo-memoria. Como se ve en la figura, la cuspide corresponde a la memoria mas cara, rapida y de menor capacidad, mientras que la base corresponde a la memoria con mayor almacenamiento, menor costo, y mas lenta.</p>\n",
    "<img src=\"https://jesusfernandeztoledo.com/wp-content/uploads/2020/01/jerarqu%C3%ADa-memoria.png\">\n",
    "<p><center>Imagen tomada de:<a>https://jesusfernandeztoledo.com/jerarquia-de-memoria/</a></center></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Funcionamiento CPU</h4>\n",
    "<p>En la actualidad contamos con procesadores con multiples nucleos. Basicamente son dos o mas procesadores identicos conectados a una misma memoria principal, a esto se le llama <em>Symmetric multiprocessing</em>, o SMP. Cada uno de estos procesadores tiene una formula sencilla para calcular el tiempo de la CPU: </p>\n",
    "<p></p>\n",
    "<p><center><strong>CPU time</strong> = number of instructions × (cycles/instruction) × cycle time.</center></p>\n",
    "<p></p>\n",
    "<p>Donde \"CPU Time\" es el tiempo requerido por un programa, \"number of instructions\" es el total de instrucciones de nivel de máquina que el programa requiere, \"cycles/instruction\" son el número de ciclos del reloj que cada instrucción requiere, y \"cycle time\" es el tiempo que se demora la CPU en hacer un ciclo.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4>Computación en Paralelo</h4>\n",
    "<p>En pocas palabras, la computación en paralelo es el uso simultaneo de multiples recursos de computo para resolver un problema <em>(Barney B,)</em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Procedimientos</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>C#</h3>\n",
    "<p>C# fue el lenguaje que usamos para crear un método que nos creara un vector y una <a href=\"https://es.wikipedia.org/wiki/Matriz_de_diagonal_estrictamente_dominante\"> matriz estrictamente diagonalmente dominante</a> y se guardaran en un archivo .txt que son separadas por comas (,) y saltos de línea por cada fila</p>\n",
    "<p>Una de las razones por las que escogimos C#, es que además de ser el lenguaje más nuevo de la familia de C es que es un lenguaje seguro pero flexible, además de tener un buen manejo de la memoria teniendo una recolección de basura automática </p>\n",
    "<h4>Jacobi</h4>\n",
    "<p>Al usar el método de Jacobi, realizado con la definición <a href=\"https://en.wikipedia.org/wiki/Jacobi_method\"> Jacobi </a> del pseudocodigo y teniendo en cuenta que la matriz dada debe ser estrictamente diagonalmente dominante creamos su respectivo método en C#, además de agregarle otros parámetros, como lo son la cantidad de iteraciones a hacer y si quiere ver el resultado para cada iteración o solo la última (siendo la última iteración o en la que para por criterio de convergencia por error) en este algoritmo solo se usan librerías para poder crear matrices y vectores, mas no para sus operaciones aritméticas</p>\n",
    "<h5>Jacobi Paralelo</h5>\n",
    "<p>Aplicar \"paralelismo\" a Jacobi se hace de manera sencilla ya que es un método naturalmente paralelisable debido a como se resuelve su algoritmo, el paralelismo es aplicado al hacer una distribución de las columnas, ya que para cada iteración a cada hilo se le dan un numero de columnas y estas resuelven sus respectivas columnas para al final tener el resultado completo</p>\n",
    "<h4>Gauss-Seidel</h4>\n",
    "<p>Aplicar el método de <a href=\"https://es.wikipedia.org/wiki/M%C3%A9todo_de_Gauss-Seidel\"> Gauss-Seidel </a> en C# fue de la misma manera que como se implementó Jacobi   </p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Referencias:</h2>\n",
    "<ol>\n",
    "    <li>https://es.wikipedia.org/wiki/Computaci%C3%B3n_de_alto_rendimiento</li>\n",
    "    <li>https://en.wikipedia.org/wiki/Jacobi_method</li>\n",
    "    <li>https://en.wikipedia.org/wiki/Diagonally_dominant_matrix</li>               <li>https://en.wikipedia.org/wiki/Gauss%E2%80%93Seidel_method</li>\n",
    "    <li>https://numpy.org/devdocs</li>\n",
    "    <li>https://supercomputing.iitd.ac.in/?info</li>\n",
    "    <li>https://jesusfernandeztoledo.com/jerarquia-de-memoria/</li>\n",
    "    <li>https://hpc.llnl.gov/training/tutorials/introduction-parallel-computing-tutorial</li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
